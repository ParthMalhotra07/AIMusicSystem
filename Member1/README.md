# ğŸµ Audio Feature Engineering Module

> **Transform raw audio into mathematical "fingerprints" for AI-powered music recommendation.**

This module eliminates metadata dependency by analyzing raw audio signals mathematicallyâ€”enabling music recommendations based purely on how songs *sound*, not how they're tagged.

---

## ğŸ¯ Overview

| Feature | Description |
|---------|-------------|
| **~170D Vector** | Fixed-length feature vector regardless of song duration |
| **3 Feature Categories** | Timbral (texture), Rhythmic (tempo), Harmonic (pitch) |
| **Multiple Exports** | CSV, NumPy (.npy), Parquet formats |
| **Batch Processing** | Process entire directories with progress tracking |

---

## ğŸš€ Quick Start

### Installation

```bash
cd Member1
pip install -r requirements.txt
```

### Single File Processing

```bash
python main.py --input song.mp3 --output features.csv
```

### Batch Processing

```bash
python main.py --input_dir ./music --output_dir ./output --format parquet
```

---

## ğŸ“Š Feature Vector Breakdown

### Timbral Features (Sound Texture)
| Feature | Dims | Description |
|---------|------|-------------|
| MFCCs | 13 Ã— 4 | Spectral envelope "fingerprint" |
| Spectral Centroid | 1 Ã— 4 | Brightness of sound |
| Spectral Contrast | 7 Ã— 4 | Peak-valley differences |
| Zero-Crossing Rate | 1 Ã— 4 | Noisiness indicator |

### Rhythmic Features (Energy)
| Feature | Dims | Description |
|---------|------|-------------|
| Tempo | 1 | BPM estimation |
| Onset Strength | 1 Ã— 4 | Attack patterns |
| Beat Strength | 1 Ã— 4 | Rhythm intensity |

### Harmonic Features (Pitch)
| Feature | Dims | Description |
|---------|------|-------------|
| Chroma | 12 Ã— 4 | Pitch class distribution |
| Tonnetz | 6 Ã— 4 | Harmonic relationships |

*Each time-varying feature has 4 statistics: mean, std, skew, kurtosis*

---

## ğŸ”§ Python API

```python
from pipeline.extractor import AudioFeatureExtractor
from pipeline.scaler import ZScoreScaler

# Initialize
extractor = AudioFeatureExtractor()

# Extract features with metadata
features, metadata = extractor.process_file('song.mp3', return_metadata=True)

print(f"Tempo: {metadata['tempo_bpm']:.1f} BPM")
print(f"Key: {metadata['key']}")
print(f"Features: {len(features)} dimensions")

# Batch processing
features_matrix = extractor.process_batch(['song1.mp3', 'song2.mp3'])

# Scale features for AI
scaler = ZScoreScaler()
features_scaled = scaler.fit_transform(features_matrix)
```

---

## ğŸ“ Project Structure

```
Member1/
â”œâ”€â”€ main.py              # CLI entry point
â”œâ”€â”€ config.py            # Configuration
â”œâ”€â”€ requirements.txt     # Dependencies
â”œâ”€â”€ preprocessing/       # Audio loading & spectral transforms
â”œâ”€â”€ features/           # Feature extractors (timbral, rhythmic, harmonic)
â”œâ”€â”€ pipeline/           # Main extraction pipeline & scalers
â”œâ”€â”€ export/             # CSV, NPY, Parquet exporters
â””â”€â”€ tests/              # Unit tests (43 tests, all passing)
```

---

## ğŸ§ª Running Tests

```bash
python3 -m pytest tests/ -v
```

---

## ğŸ“¤ Output Formats

| Format | Use Case |
|--------|----------|
| **CSV** | Human-readable, spreadsheet import |
| **NPY** | Fast NumPy loading |
| **Parquet** | Columnar queries, compression, Spark/Dask |

---

## ğŸ”— Integration with Other Modules

- **Member 2 (Clustering)**: Use exported features for unsupervised clustering
- **Member 3 (UI/Recs)**: Query for similar songs using feature vectors

Features are **independent** of downstream modelsâ€”change the AI, keep the same ground truth.

---

## ğŸ“‹ CLI Reference

```
python main.py [OPTIONS]

Options:
  --input, -i      Single audio file path
  --input_dir, -d  Directory of audio files
  --output, -o     Output file path
  --output_dir     Output directory (default: ./output)
  --format, -f     Output format: csv, npy, parquet (default: parquet)
  --sample_rate    Target sample rate (default: 22050)
  --scale          Scaling: none, minmax, zscore (default: zscore)
  --recursive, -r  Search subdirectories
  --quiet, -q      Suppress progress output
```

---

## ğŸ“– Mathematics Behind the Features

### Why These Features?

1. **MFCCs** capture the *shape* of the spectral envelopeâ€”what makes a piano different from a guitar
2. **Chroma** captures *which notes* are present, regardless of octaveâ€”perfect for harmonic analysis
3. **Tempo** captures the *speed* and *danceability* of the track
4. **Statistical aggregation** (mean, std, skew, kurtosis) summarizes how features change over time

### Fixed-Length Output

The key innovation is **global pooling**: by computing statistics over all time frames, a 3-minute song and a 10-minute song both produce a vector of the **same dimension**.

---

*Built for the AI Music Recommendation System â€” Member 1: Audio Signal & Feature Engineering*
